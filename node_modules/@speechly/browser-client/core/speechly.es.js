/**
 * All possible states of a Speechly API client. Failed, NoBrowserSupport and NoAudioConsent states are non-recoverable
 * erroneous states, which should be handled by the end user, according to the semantics of an application.
 * Other states can also be utilized for e.g. enabling and disabling recording buttons or showing the status in the app.
 * It is also possible to use arithmetics for state comparison, e.g. `if (state < speechly.ClientState.Disconnected)`,
 * to react to non-recoverable states.
 * @public
 */
var ClientState;
(function (ClientState) {
    ClientState[ClientState["Failed"] = 0] = "Failed";
    ClientState[ClientState["NoBrowserSupport"] = 1] = "NoBrowserSupport";
    ClientState[ClientState["NoAudioConsent"] = 2] = "NoAudioConsent";
    ClientState[ClientState["__UnrecoverableErrors"] = 3] = "__UnrecoverableErrors";
    ClientState[ClientState["Disconnected"] = 4] = "Disconnected";
    ClientState[ClientState["Disconnecting"] = 5] = "Disconnecting";
    ClientState[ClientState["Connecting"] = 6] = "Connecting";
    ClientState[ClientState["Preinitialized"] = 7] = "Preinitialized";
    ClientState[ClientState["Initializing"] = 8] = "Initializing";
    ClientState[ClientState["Connected"] = 9] = "Connected";
    ClientState[ClientState["Stopping"] = 10] = "Stopping";
    ClientState[ClientState["Starting"] = 11] = "Starting";
    ClientState[ClientState["Recording"] = 12] = "Recording";
})(ClientState || (ClientState = {}));

/**
 * Converts client state value to a string, which could be useful for debugging or metrics.
 * @param state - the state of the client
 * @public
 */
function stateToString(state) {
    var _a;
    return (_a = states.get(state)) !== null && _a !== void 0 ? _a : unknown;
}
// TODO: generate this from the enum.
const unknown = 'Unknown';
const states = new Map([
    [ClientState.Failed, 'Failed'],
    [ClientState.NoBrowserSupport, 'NoBrowserSupport'],
    [ClientState.NoAudioConsent, 'NoAudioConsent'],
    [ClientState.Disconnecting, 'Disconnecting'],
    [ClientState.Disconnected, 'Disconnected'],
    [ClientState.Connecting, 'Connecting'],
    [ClientState.Preinitialized, 'Preinitialized'],
    [ClientState.Initializing, 'Initializing'],
    [ClientState.Connected, 'Connected'],
    [ClientState.Stopping, 'Stopping'],
    [ClientState.Starting, 'Starting'],
    [ClientState.Recording, 'Recording'],
]);

/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */

function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}

// Unique ID creation requires a high quality random # generator. In the browser we therefore
// require the crypto API and do not support built-in fallback to lower quality random number
// generators (like Math.random()).
var getRandomValues;
var rnds8 = new Uint8Array(16);
function rng() {
  // lazy load so that environments that need to polyfill have a chance to do so
  if (!getRandomValues) {
    // getRandomValues needs to be invoked in a context where "this" is a Crypto implementation. Also,
    // find the complete implementation of crypto (msCrypto) on IE11.
    getRandomValues = typeof crypto !== 'undefined' && crypto.getRandomValues && crypto.getRandomValues.bind(crypto) || typeof msCrypto !== 'undefined' && typeof msCrypto.getRandomValues === 'function' && msCrypto.getRandomValues.bind(msCrypto);

    if (!getRandomValues) {
      throw new Error('crypto.getRandomValues() not supported. See https://github.com/uuidjs/uuid#getrandomvalues-not-supported');
    }
  }

  return getRandomValues(rnds8);
}

var REGEX = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;

function validate(uuid) {
  return typeof uuid === 'string' && REGEX.test(uuid);
}

/**
 * Convert array of 16 byte values to UUID string format of the form:
 * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX
 */

var byteToHex = [];

for (var i = 0; i < 256; ++i) {
  byteToHex.push((i + 0x100).toString(16).substr(1));
}

function stringify(arr) {
  var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  // Note: Be careful editing this code!  It's been tuned for performance
  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434
  var uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one
  // of the following:
  // - One or more input array values don't map to a hex octet (leading to
  // "undefined" in the uuid)
  // - Invalid input values for the RFC `version` or `variant` fields

  if (!validate(uuid)) {
    throw TypeError('Stringified UUID is invalid');
  }

  return uuid;
}

function v4(options, buf, offset) {
  options = options || {};
  var rnds = options.random || (options.rng || rng)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`

  rnds[6] = rnds[6] & 0x0f | 0x40;
  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided

  if (buf) {
    offset = offset || 0;

    for (var i = 0; i < 16; ++i) {
      buf[offset + i] = rnds[i];
    }

    return buf;
  }

  return stringify(rnds);
}

var commonjsGlobal = typeof globalThis !== 'undefined' ? globalThis : typeof window !== 'undefined' ? window : typeof global !== 'undefined' ? global : typeof self !== 'undefined' ? self : {};

var base64 = {exports: {}};

/*! http://mths.be/base64 v0.1.0 by @mathias | MIT license */

(function (module, exports) {
(function(root) {

	// Detect free variables `exports`.
	var freeExports = exports;

	// Detect free variable `module`.
	var freeModule = module &&
		module.exports == freeExports && module;

	// Detect free variable `global`, from Node.js or Browserified code, and use
	// it as `root`.
	var freeGlobal = typeof commonjsGlobal == 'object' && commonjsGlobal;
	if (freeGlobal.global === freeGlobal || freeGlobal.window === freeGlobal) {
		root = freeGlobal;
	}

	/*--------------------------------------------------------------------------*/

	var InvalidCharacterError = function(message) {
		this.message = message;
	};
	InvalidCharacterError.prototype = new Error;
	InvalidCharacterError.prototype.name = 'InvalidCharacterError';

	var error = function(message) {
		// Note: the error messages used throughout this file match those used by
		// the native `atob`/`btoa` implementation in Chromium.
		throw new InvalidCharacterError(message);
	};

	var TABLE = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
	// http://whatwg.org/html/common-microsyntaxes.html#space-character
	var REGEX_SPACE_CHARACTERS = /[\t\n\f\r ]/g;

	// `decode` is designed to be fully compatible with `atob` as described in the
	// HTML Standard. http://whatwg.org/html/webappapis.html#dom-windowbase64-atob
	// The optimized base64-decoding algorithm used is based on @atk’s excellent
	// implementation. https://gist.github.com/atk/1020396
	var decode = function(input) {
		input = String(input)
			.replace(REGEX_SPACE_CHARACTERS, '');
		var length = input.length;
		if (length % 4 == 0) {
			input = input.replace(/==?$/, '');
			length = input.length;
		}
		if (
			length % 4 == 1 ||
			// http://whatwg.org/C#alphanumeric-ascii-characters
			/[^+a-zA-Z0-9/]/.test(input)
		) {
			error(
				'Invalid character: the string to be decoded is not correctly encoded.'
			);
		}
		var bitCounter = 0;
		var bitStorage;
		var buffer;
		var output = '';
		var position = -1;
		while (++position < length) {
			buffer = TABLE.indexOf(input.charAt(position));
			bitStorage = bitCounter % 4 ? bitStorage * 64 + buffer : buffer;
			// Unless this is the first of a group of 4 characters…
			if (bitCounter++ % 4) {
				// …convert the first 8 bits to a single ASCII character.
				output += String.fromCharCode(
					0xFF & bitStorage >> (-2 * bitCounter & 6)
				);
			}
		}
		return output;
	};

	// `encode` is designed to be fully compatible with `btoa` as described in the
	// HTML Standard: http://whatwg.org/html/webappapis.html#dom-windowbase64-btoa
	var encode = function(input) {
		input = String(input);
		if (/[^\0-\xFF]/.test(input)) {
			// Note: no need to special-case astral symbols here, as surrogates are
			// matched, and the input is supposed to only contain ASCII anyway.
			error(
				'The string to be encoded contains characters outside of the ' +
				'Latin1 range.'
			);
		}
		var padding = input.length % 3;
		var output = '';
		var position = -1;
		var a;
		var b;
		var c;
		var buffer;
		// Make sure any padding is handled outside of the loop.
		var length = input.length - padding;

		while (++position < length) {
			// Read three bytes, i.e. 24 bits.
			a = input.charCodeAt(position) << 16;
			b = input.charCodeAt(++position) << 8;
			c = input.charCodeAt(++position);
			buffer = a + b + c;
			// Turn the 24 bits into four chunks of 6 bits each, and append the
			// matching character for each of them to the output.
			output += (
				TABLE.charAt(buffer >> 18 & 0x3F) +
				TABLE.charAt(buffer >> 12 & 0x3F) +
				TABLE.charAt(buffer >> 6 & 0x3F) +
				TABLE.charAt(buffer & 0x3F)
			);
		}

		if (padding == 2) {
			a = input.charCodeAt(position) << 8;
			b = input.charCodeAt(++position);
			buffer = a + b;
			output += (
				TABLE.charAt(buffer >> 10) +
				TABLE.charAt((buffer >> 4) & 0x3F) +
				TABLE.charAt((buffer << 2) & 0x3F) +
				'='
			);
		} else if (padding == 1) {
			buffer = input.charCodeAt(position);
			output += (
				TABLE.charAt(buffer >> 2) +
				TABLE.charAt((buffer << 4) & 0x3F) +
				'=='
			);
		}

		return output;
	};

	var base64 = {
		'encode': encode,
		'decode': decode,
		'version': '0.1.0'
	};

	// Some AMD build optimizers, like r.js, check for specific condition patterns
	// like the following:
	if (freeExports && !freeExports.nodeType) {
		if (freeModule) { // in Node.js or RingoJS v0.8.0+
			freeModule.exports = base64;
		} else { // in Narwhal or RingoJS v0.7.0-
			for (var key in base64) {
				base64.hasOwnProperty(key) && (freeExports[key] = base64[key]);
			}
		}
	} else { // in Rhino or a web browser
		root.base64 = base64;
	}

}(commonjsGlobal));
}(base64, base64.exports));

const minTokenValidTime = 60 * 60 * 1000; // 1 hour
function fetchToken(baseUrl, projectId, appId, deviceId, fetcher = fetch, nowFn = Date.now) {
    var _a;
    return __awaiter(this, void 0, void 0, function* () {
        let body;
        if (projectId !== undefined) {
            body = { projectId, deviceId };
        }
        else {
            body = { appId, deviceId };
        }
        const response = yield fetcher(baseUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
            },
            body: JSON.stringify(body),
        });
        const json = yield response.json();
        if (response.status !== 200) {
            throw Error((_a = json.error) !== null && _a !== void 0 ? _a : `Speechly API login request failed with ${response.status}`);
        }
        if (json.access_token === undefined) {
            throw Error('Invalid login response from Speechly API');
        }
        if (!validateToken(json.access_token, projectId, appId, deviceId, nowFn)) {
            throw Error('Invalid token received from Speechly API');
        }
        return json.access_token;
    });
}
function validateToken(token, projectId, appId, deviceId, now = Date.now) {
    const decoded = decodeToken(token);
    if (decoded.expiresAtMs - now() < minTokenValidTime) {
        return false;
    }
    if (decoded.appId !== appId || decoded.projectId !== projectId) {
        return false;
    }
    if (decoded.deviceId !== deviceId) {
        return false;
    }
    return true;
}
function decodeToken(token) {
    const b = token.split('.')[1];
    let body;
    try {
        body = JSON.parse(base64.exports.decode(b));
    }
    catch (e) {
        throw new Error('Error decoding Speechly token!');
    }
    return {
        appId: body.appId,
        projectId: body.projectId,
        deviceId: body.deviceId,
        configId: body.configId,
        scopes: body.scope.split(' '),
        issuer: body.iss,
        audience: body.aud,
        expiresAtMs: body.exp * 1000, // JWT exp is in seconds, convert to ms, since that's what JS works with.
    };
}

/**
 * Default sample rate for microphone streams.
 * @public
 */
const DefaultSampleRate = 16000;
/**
 * Error to be thrown when the microphone was accessed before it was initialized.
 * @public
 */
const ErrNotInitialized = new Error('Microphone is not initialized');
/**
 * Error to be thrown when the initialize method of a Microphone instance is called more than once.
 * @public
 */
const ErrAlreadyInitialized = new Error('Microphone is already initialized');
/**
 * Error to be thrown when the device does not support the Microphone instance's target audio APIs.
 * @public
 */
const ErrDeviceNotSupported = new Error('Current device does not support microphone API');
/**
 * Error to be thrown when user did not give consent to the application to record audio.
 * @public
 */
const ErrNoAudioConsent = new Error('Microphone consent is no given');
/**
 * Error to be thrown when user tries to change appId without project login.
 * @public
 */
const ErrAppIdChangeWithoutProjectLogin = new Error('AppId changed without project login');

var audioworklet = `
// Indices for the Control SAB.
const CONTROL = {
  'WRITE_INDEX': 0,
  'FRAMES_AVAILABLE': 1,
  'LOCK': 2,
};

class SpeechlyProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    this._initialized = false;
    this.debug = false;
    this.port.onmessage = this._initialize.bind(this);
  }

  _initialize(event) {
    this.controlSAB = new Int32Array(event.data.controlSAB);
    this.dataSAB = new Float32Array(event.data.dataSAB);
    this.debug = event.data.debug;
    this.sharedBufferSize = this.dataSAB.length;
    this.buffer = new Float32Array(0);
    this._initialized = true;
  }

  _transferDataToSharedBuffer(data) {
    this.controlSAB[CONTROL.LOCK] = 1
    let inputWriteIndex = this.controlSAB[CONTROL.WRITE_INDEX]
    if (this.controlSAB[CONTROL.FRAMES_AVAILABLE] > 0) {
      if (inputWriteIndex + data.length > this.sharedBufferSize) {
        // console.log('buffer overflow')
        inputWriteIndex = 0
      }
    }
    this.dataSAB.set(data, inputWriteIndex)
    this.controlSAB[CONTROL.WRITE_INDEX] = inputWriteIndex + data.length
    this.controlSAB[CONTROL.FRAMES_AVAILABLE] = inputWriteIndex + data.length
    this.controlSAB[CONTROL.LOCK] = 0
  }

  _pushData(data) {
    if (this.debug) {
      const signalEnergy = getStandardDeviation(data)
      this.port.postMessage({
        type: 'STATS',
        signalEnergy: signalEnergy
      });
    }

    if (this.buffer.length > this.sharedBufferSize) {
      const dataToTransfer = this.buffer.subarray(0, this.sharedBufferSize)
      this._transferDataToSharedBuffer(dataToTransfer)
      this.buffer = this.buffer.subarray(this.sharedBufferSize)
    }
    let concat = new Float32Array(this.buffer.length + data.length)
    concat.set(this.buffer)
    concat.set(data, this.buffer.length)
    this.buffer = concat
  }

  process(inputs, outputs, parameters) {
    const inputChannelData = inputs[0][0];
      if (inputChannelData !== undefined) {
        if (this.controlSAB && this.dataSAB) {
          this._pushData(inputChannelData);
        } else {
          this.port.postMessage({
            type: 'DATA',
            frames: inputChannelData
          });
        }
      }
      
      return true;
  }
}

function getStandardDeviation(array) {
  const n = array.length
  const mean = array.reduce((a, b) => a + b) / n
  return Math.sqrt(array.map(x => Math.pow(x - mean, 2)).reduce((a, b) => a + b) / n)
}

registerProcessor('speechly-worklet', SpeechlyProcessor);
`;

const audioProcessEvent = 'audioprocess';
const baseBufferSize = 4096;
class BrowserMicrophone {
    constructor(isWebkit, sampleRate, apiClient, debug = false) {
        this.initialized = false;
        this.muted = false;
        this.stats = {
            maxSignalEnergy: 0.0,
        };
        this.handleAudio = (array) => {
            if (this.muted) {
                return;
            }
            if (array.length > 0) {
                this.apiClient.sendAudio(array);
            }
        };
        this.isWebkit = isWebkit;
        this.apiClient = apiClient;
        this.sampleRate = sampleRate;
        this.debug = debug;
    }
    initialize(audioContext, mediaStreamConstraints) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            if (((_a = window.navigator) === null || _a === void 0 ? void 0 : _a.mediaDevices) === undefined) {
                throw ErrDeviceNotSupported;
            }
            this.audioContext = audioContext;
            this.resampleRatio = this.audioContext.sampleRate / this.sampleRate;
            try {
                this.mediaStream = yield window.navigator.mediaDevices.getUserMedia(mediaStreamConstraints);
            }
            catch (_b) {
                throw ErrNoAudioConsent;
            }
            this.audioTrack = this.mediaStream.getAudioTracks()[0];
            // Start audio context if we are dealing with a non-WebKit browser.
            //
            // Non-webkit browsers (currently only Chrome on Android)
            // require that user media is obtained before resuming the audio context.
            //
            // If audio context is attempted to be resumed before `mediaDevices.getUserMedia`,
            // `audioContext.resume()` will hang indefinitely, without being resolved or rejected.
            if (!this.isWebkit) {
                yield this.audioContext.resume();
            }
            if (window.AudioWorkletNode !== undefined) {
                const blob = new Blob([audioworklet], { type: 'text/javascript' });
                const blobURL = window.URL.createObjectURL(blob);
                yield this.audioContext.audioWorklet.addModule(blobURL);
                const speechlyNode = new AudioWorkletNode(this.audioContext, 'speechly-worklet');
                this.audioContext.createMediaStreamSource(this.mediaStream).connect(speechlyNode);
                speechlyNode.connect(this.audioContext.destination);
                // @ts-ignore
                if (window.SharedArrayBuffer !== undefined) {
                    // Chrome, Edge, Firefox, Firefox Android
                    // @ts-ignore
                    const controlSAB = new window.SharedArrayBuffer(4 * Int32Array.BYTES_PER_ELEMENT);
                    // @ts-ignore
                    const dataSAB = new window.SharedArrayBuffer(1024 * Float32Array.BYTES_PER_ELEMENT);
                    this.apiClient.postMessage({
                        type: 'SET_SHARED_ARRAY_BUFFERS',
                        controlSAB,
                        dataSAB,
                    });
                    speechlyNode.port.postMessage({
                        type: 'SET_SHARED_ARRAY_BUFFERS',
                        controlSAB,
                        dataSAB,
                        debug: this.debug,
                    });
                }
                else {
                    // Opera, Chrome Android, Webview Anroid
                    if (this.debug) {
                        console.log('[SpeechlyClient]', 'can not use SharedArrayBuffer');
                    }
                }
                speechlyNode.port.onmessage = (event) => {
                    switch (event.data.type) {
                        case 'STATS':
                            if (event.data.signalEnergy > this.stats.maxSignalEnergy) {
                                this.stats.maxSignalEnergy = event.data.signalEnergy;
                            }
                            break;
                        case 'DATA':
                            this.handleAudio(event.data.frames);
                            break;
                    }
                };
            }
            else {
                if (this.debug) {
                    console.log('[SpeechlyClient]', 'can not use AudioWorkletNode');
                }
                // Safari, iOS Safari and Internet Explorer
                if (this.isWebkit) {
                    // Multiply base buffer size of 4 kB by the resample ratio rounded up to the next power of 2.
                    // i.e. for 48 kHz to 16 kHz downsampling, this will be 4096 (base) * 4 = 16384.
                    const bufSize = baseBufferSize * Math.pow(2, Math.ceil(Math.log(this.resampleRatio) / Math.log(2)));
                    this.audioProcessor = this.audioContext.createScriptProcessor(bufSize, 1, 1);
                }
                else {
                    this.audioProcessor = this.audioContext.createScriptProcessor(undefined, 1, 1);
                }
                this.audioContext.createMediaStreamSource(this.mediaStream).connect(this.audioProcessor);
                this.audioProcessor.connect(this.audioContext.destination);
                this.audioProcessor.addEventListener(audioProcessEvent, (event) => {
                    this.handleAudio(event.inputBuffer.getChannelData(0));
                });
            }
            this.initialized = true;
            this.mute();
        });
    }
    close() {
        return __awaiter(this, void 0, void 0, function* () {
            this.mute();
            if (!this.initialized) {
                throw ErrNotInitialized;
            }
            const t = this.audioTrack;
            t.enabled = false;
            // Stop all media tracks
            const stream = this.mediaStream;
            stream.getTracks().forEach(t => t.stop());
            // Disconnect and stop ScriptProcessorNode
            if (this.audioProcessor != null) {
                const proc = this.audioProcessor;
                proc.disconnect();
            }
            // Unset all audio infrastructure
            this.mediaStream = undefined;
            this.audioTrack = undefined;
            this.audioProcessor = undefined;
            this.initialized = false;
        });
    }
    mute() {
        this.muted = true;
    }
    unmute() {
        this.muted = false;
    }
    /**
     * print statistics to console
     */
    printStats() {
        if (this.audioTrack != null) {
            const settings = this.audioTrack.getSettings();
            console.log(this.audioTrack.label, this.audioTrack.readyState);
            // @ts-ignore
            console.log('channelCount', settings.channelCount);
            // @ts-ignore
            console.log('latency', settings.latency);
            // @ts-ignore
            console.log('autoGainControl', settings.autoGainControl);
        }
        console.log('maxSignalEnergy', this.stats.maxSignalEnergy);
    }
}

/**
 * Known WebSocket response types.
 * @public
 */
var WebsocketResponseType;
(function (WebsocketResponseType) {
    WebsocketResponseType["Opened"] = "WEBSOCKET_OPEN";
    WebsocketResponseType["Closed"] = "WEBSOCKET_CLOSED";
    WebsocketResponseType["SourceSampleRateSetSuccess"] = "SOURSE_SAMPLE_RATE_SET_SUCCESS";
    WebsocketResponseType["Started"] = "started";
    WebsocketResponseType["Stopped"] = "stopped";
    WebsocketResponseType["SegmentEnd"] = "segment_end";
    WebsocketResponseType["Transcript"] = "transcript";
    WebsocketResponseType["Entity"] = "entity";
    WebsocketResponseType["Intent"] = "intent";
    WebsocketResponseType["TentativeTranscript"] = "tentative_transcript";
    WebsocketResponseType["TentativeEntities"] = "tentative_entities";
    WebsocketResponseType["TentativeIntent"] = "tentative_intent";
})(WebsocketResponseType || (WebsocketResponseType = {}));

var worker = `/**
 * Known WebSocket response types.
 * @public
 */
var WebsocketResponseType;
(function (WebsocketResponseType) {
    WebsocketResponseType["Opened"] = "WEBSOCKET_OPEN";
    WebsocketResponseType["SourceSampleRateSetSuccess"] = "SOURSE_SAMPLE_RATE_SET_SUCCESS";
    WebsocketResponseType["Started"] = "started";
    WebsocketResponseType["Stopped"] = "stopped";
})(WebsocketResponseType || (WebsocketResponseType = {}));
var CONTROL = {
    WRITE_INDEX: 0,
    FRAMES_AVAILABLE: 1,
    LOCK: 2
};
var WebsocketClient = /** @class */ (function () {
    function WebsocketClient(ctx) {
        var _this = this;
        this.isContextStarted = false;
        this.isStartContextConfirmed = false;
        this.shouldResendLastFramesSent = false;
        this.buffer = new Float32Array(0);
        this.lastFramesSent = new Int16Array(0); // to re-send after switch context
        this.debug = false;
        this.initialized = false;
        // WebSocket's close handler, called e.g. when
        // - normal close (code 1000)
        // - network unreachable or unable to (re)connect (code 1006)
        // List of CloseEvent.code values: https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent/code
        this.onWebsocketClose = function (event) {
            if (_this.debug) {
                console.log('[SpeechlyClient]', 'onWebsocketClose');
            }
            _this.websocket.removeEventListener('open', _this.onWebsocketOpen);
            _this.websocket.removeEventListener('message', _this.onWebsocketMessage);
            _this.websocket.removeEventListener('error', _this.onWebsocketError);
            _this.websocket.removeEventListener('close', _this.onWebsocketClose);
            _this.websocket = undefined;
            _this.workerCtx.postMessage({ type: 'WEBSOCKET_CLOSED', code: event.code, reason: event.reason, wasClean: event.wasClean });
        };
        this.onWebsocketOpen = function (_event) {
            if (_this.debug) {
                console.log('[SpeechlyClient]', 'websocket opened');
            }
            if (_this.isContextStarted && !_this.isStartContextConfirmed) {
                _this.send(_this.outbox);
            }
            _this.workerCtx.postMessage({ type: 'WEBSOCKET_OPEN' });
        };
        this.onWebsocketError = function (_event) {
            if (_this.debug) {
                console.log('[SpeechlyClient]', 'websocket error');
            }
        };
        this.onWebsocketMessage = function (event) {
            var response;
            try {
                response = JSON.parse(event.data);
            }
            catch (e) {
                console.error('[SpeechlyClient] Error parsing response from the server:', e);
                return;
            }
            if (response.type === WebsocketResponseType.Started) {
                _this.isStartContextConfirmed = true;
                if (_this.shouldResendLastFramesSent) {
                    _this.resendLastFrames();
                    _this.shouldResendLastFramesSent = false;
                }
            }
            _this.workerCtx.postMessage(response);
        };
        this.workerCtx = ctx;
    }
    WebsocketClient.prototype.init = function (apiUrl, authToken, targetSampleRate, debug) {
        this.debug = debug;
        if (this.debug) {
            console.log('[SpeechlyClient]', 'initialize worker');
        }
        this.apiUrl = apiUrl;
        this.authToken = authToken;
        this.targetSampleRate = targetSampleRate;
        this.initialized = true;
        this.isContextStarted = false;
        this.connect(0);
    };
    WebsocketClient.prototype.setSourceSampleRate = function (sourceSampleRate) {
        this.sourceSampleRate = sourceSampleRate;
        this.resampleRatio = this.sourceSampleRate / this.targetSampleRate;
        if (this.debug) {
            console.log('[SpeechlyClient]', 'resampleRatio', this.resampleRatio);
        }
        if (this.resampleRatio > 1) {
            this.filter = generateFilter(this.sourceSampleRate, this.targetSampleRate, 127);
        }
        this.workerCtx.postMessage({ type: 'SOURSE_SAMPLE_RATE_SET_SUCCESS' });
        if (isNaN(this.resampleRatio)) {
            throw Error("resampleRatio is NaN source rate is ".concat(this.sourceSampleRate, " and target rate is ").concat(this.targetSampleRate));
        }
    };
    WebsocketClient.prototype.setSharedArrayBuffers = function (controlSAB, dataSAB) {
        this.controlSAB = new Int32Array(controlSAB);
        this.dataSAB = new Float32Array(dataSAB);
        var audioHandleInterval = this.dataSAB.length / 32; // ms
        if (this.debug) {
            console.log('[SpeechlyClient]', 'Audio handle interval', audioHandleInterval, 'ms');
        }
        setInterval(this.sendAudioFromSAB.bind(this), audioHandleInterval);
    };
    WebsocketClient.prototype.connect = function (timeout) {
        if (timeout === void 0) { timeout = 1000; }
        if (this.debug) {
            console.log('[SpeechlyClient]', 'connect in ', timeout / 1000, 'sec');
        }
        setTimeout(this.initializeWebsocket.bind(this), timeout);
    };
    WebsocketClient.prototype.initializeWebsocket = function () {
        if (this.debug) {
            console.log('[SpeechlyClient]', 'connecting to ', this.apiUrl);
        }
        this.websocket = new WebSocket(this.apiUrl, this.authToken);
        this.websocket.addEventListener('open', this.onWebsocketOpen);
        this.websocket.addEventListener('message', this.onWebsocketMessage);
        this.websocket.addEventListener('error', this.onWebsocketError);
        this.websocket.addEventListener('close', this.onWebsocketClose);
    };
    WebsocketClient.prototype.isOpen = function () {
        return this.websocket !== undefined && this.websocket.readyState === this.websocket.OPEN;
    };
    WebsocketClient.prototype.resendLastFrames = function () {
        if (this.lastFramesSent.length > 0) {
            this.send(this.lastFramesSent);
            this.lastFramesSent = new Int16Array(0);
        }
    };
    WebsocketClient.prototype.sendAudio = function (audioChunk) {
        if (!this.isContextStarted) {
            return;
        }
        if (audioChunk.length > 0) {
            if (this.resampleRatio > 1) {
                // Downsampling
                this.send(this.downsample(audioChunk));
            }
            else {
                this.send(float32ToInt16(audioChunk));
            }
        }
    };
    WebsocketClient.prototype.sendAudioFromSAB = function () {
        if (!this.isContextStarted) {
            this.controlSAB[CONTROL.FRAMES_AVAILABLE] = 0;
            this.controlSAB[CONTROL.WRITE_INDEX] = 0;
            return;
        }
        if (this.controlSAB == undefined) {
            return;
        }
        var framesAvailable = this.controlSAB[CONTROL.FRAMES_AVAILABLE];
        var lock = this.controlSAB[CONTROL.LOCK];
        if (lock == 0 && framesAvailable > 0) {
            var data = this.dataSAB.subarray(0, framesAvailable);
            this.controlSAB[CONTROL.FRAMES_AVAILABLE] = 0;
            this.controlSAB[CONTROL.WRITE_INDEX] = 0;
            if (data.length > 0) {
                var frames_1;
                if (this.resampleRatio > 1) {
                    frames_1 = this.downsample(data);
                }
                else {
                    frames_1 = float32ToInt16(data);
                }
                this.send(frames_1);
                // 16000 per second, 1000 in 100 ms
                // save last 250 ms
                if (this.lastFramesSent.length > 1024 * 4) {
                    this.lastFramesSent = frames_1;
                }
                else {
                    var concat = new Int16Array(this.lastFramesSent.length + frames_1.length);
                    concat.set(this.lastFramesSent);
                    concat.set(frames_1, this.lastFramesSent.length);
                    this.lastFramesSent = concat;
                }
            }
        }
    };
    WebsocketClient.prototype.startContext = function (appId) {
        if (this.isContextStarted) {
            console.log('Cant start context: it has been already started');
            return;
        }
        this.isContextStarted = true;
        this.isStartContextConfirmed = false;
        if (appId !== undefined) {
            this.outbox = JSON.stringify({ event: 'start', appId: appId });
        }
        else {
            this.outbox = JSON.stringify({ event: 'start' });
        }
        this.send(this.outbox);
    };
    WebsocketClient.prototype.stopContext = function () {
        if (!this.websocket) {
            throw Error('Cant start context: websocket is undefined');
        }
        if (!this.isContextStarted) {
            console.log('Cant stop context: it is not started');
            return;
        }
        this.isContextStarted = false;
        this.isStartContextConfirmed = false;
        var StopEventJSON = JSON.stringify({ event: 'stop' });
        this.send(StopEventJSON);
    };
    WebsocketClient.prototype.switchContext = function (newAppId) {
        if (!this.websocket) {
            throw Error('Cant switch context: websocket is undefined');
        }
        if (!this.isContextStarted) {
            console.log('Cant switch context: it is not started');
            return;
        }
        if (newAppId == undefined) {
            console.log('Cant switch context: new app id is undefined');
            return;
        }
        this.isStartContextConfirmed = false;
        var StopEventJSON = JSON.stringify({ event: 'stop' });
        this.send(StopEventJSON);
        this.shouldResendLastFramesSent = true;
        this.send(JSON.stringify({ event: 'start', appId: newAppId }));
    };
    WebsocketClient.prototype.closeWebsocket = function (websocketCode, reason) {
        if (websocketCode === void 0) { websocketCode = 1005; }
        if (reason === void 0) { reason = "No Status Received"; }
        if (this.debug) {
            console.log('[SpeechlyClient]', 'Websocket closing');
        }
        if (!this.websocket) {
            throw Error('Websocket is not open');
        }
        this.websocket.close(websocketCode, reason);
    };
    WebsocketClient.prototype.downsample = function (input) {
        var inputBuffer = new Float32Array(this.buffer.length + input.length);
        inputBuffer.set(this.buffer, 0);
        inputBuffer.set(input, this.buffer.length);
        var outputLength = Math.ceil((inputBuffer.length - this.filter.length) / this.resampleRatio);
        var outputBuffer = new Int16Array(outputLength);
        for (var i = 0; i < outputLength; i++) {
            var offset = Math.round(this.resampleRatio * i);
            var val = 0.0;
            for (var j = 0; j < this.filter.length; j++) {
                val += inputBuffer[offset + j] * this.filter[j];
            }
            outputBuffer[i] = val * (val < 0 ? 0x8000 : 0x7fff);
        }
        var remainingOffset = Math.round(this.resampleRatio * outputLength);
        if (remainingOffset < inputBuffer.length) {
            this.buffer = inputBuffer.subarray(remainingOffset);
        }
        else {
            this.buffer = new Float32Array(0);
        }
        return outputBuffer;
    };
    WebsocketClient.prototype.send = function (data) {
        if (this.isOpen()) {
            try {
                this.websocket.send(data);
            }
            catch (error) {
                console.log('[SpeechlyClient]', 'Server connection error', error);
            }
        }
    };
    return WebsocketClient;
}());
var ctx = self;
var websocketClient = new WebsocketClient(ctx);
ctx.onmessage = function (e) {
    switch (e.data.type) {
        case 'INIT':
            websocketClient.init(e.data.apiUrl, e.data.authToken, e.data.targetSampleRate, e.data.debug);
            break;
        case 'SET_SOURSE_SAMPLE_RATE':
            websocketClient.setSourceSampleRate(e.data.sourceSampleRate);
            break;
        case 'SET_SHARED_ARRAY_BUFFERS':
            websocketClient.setSharedArrayBuffers(e.data.controlSAB, e.data.dataSAB);
            break;
        case 'CLOSE':
            websocketClient.closeWebsocket(1000, "Close requested by client");
            break;
        case 'START_CONTEXT':
            websocketClient.startContext(e.data.appId);
            break;
        case 'SWITCH_CONTEXT':
            websocketClient.switchContext(e.data.appId);
            break;
        case 'STOP_CONTEXT':
            websocketClient.stopContext();
            break;
        case 'AUDIO':
            websocketClient.sendAudio(e.data.payload);
            break;
        default:
            console.log('WORKER', e);
    }
};
function float32ToInt16(buffer) {
    var buf = new Int16Array(buffer.length);
    for (var l = 0; l < buffer.length; l++) {
        buf[l] = buffer[l] * (buffer[l] < 0 ? 0x8000 : 0x7fff);
    }
    return buf;
}
function generateFilter(sourceSampleRate, targetSampleRate, length) {
    if (length % 2 === 0) {
        throw Error('Filter length must be odd');
    }
    var cutoff = targetSampleRate / 2;
    var filter = new Float32Array(length);
    var sum = 0;
    for (var i = 0; i < length; i++) {
        var x = sinc(((2 * cutoff) / sourceSampleRate) * (i - (length - 1) / 2));
        sum += x;
        filter[i] = x;
    }
    for (var i = 0; i < length; i++) {
        filter[i] = filter[i] / sum;
    }
    return filter;
}
function sinc(x) {
    if (x === 0.0) {
        return 1.0;
    }
    var piX = Math.PI * x;
    return Math.sin(piX) / piX;
}
`;

class WebWorkerController {
    constructor() {
        this.startCbs = [];
        this.stopCbs = [];
        this.onResponseCb = () => { };
        this.onCloseCb = () => { };
        this.onWebsocketMessage = (event) => {
            const response = event.data;
            switch (response.type) {
                case WebsocketResponseType.Opened:
                    if (this.resolveInitialization != null) {
                        this.resolveInitialization();
                    }
                    break;
                case WebsocketResponseType.Closed:
                    this.onCloseCb({
                        code: event.data.code,
                        reason: event.data.reason,
                        wasClean: event.data.wasClean,
                    });
                    break;
                case WebsocketResponseType.SourceSampleRateSetSuccess:
                    if (this.resolveSourceSampleRateSet != null) {
                        this.resolveSourceSampleRateSet();
                    }
                    break;
                case WebsocketResponseType.Started:
                    this.startCbs.forEach(cb => {
                        try {
                            cb(undefined, response.audio_context);
                        }
                        catch (e) {
                            console.error('[SpeechlyClient] Error while invoking "onStart" callback:', e);
                        }
                    });
                    this.startCbs.length = 0;
                    break;
                case WebsocketResponseType.Stopped:
                    this.stopCbs.forEach(cb => {
                        try {
                            cb(undefined, response.audio_context);
                        }
                        catch (e) {
                            console.error('[SpeechlyClient] Error while invoking "onStop" callback:', e);
                        }
                    });
                    this.stopCbs.length = 0;
                    break;
                default:
                    this.onResponseCb(response);
            }
        };
        const blob = new Blob([worker], { type: 'text/javascript' });
        const blobURL = window.URL.createObjectURL(blob);
        this.worker = new Worker(blobURL);
        this.worker.addEventListener('message', this.onWebsocketMessage);
    }
    onResponse(cb) {
        this.onResponseCb = cb;
    }
    onClose(cb) {
        this.onCloseCb = cb;
    }
    initialize(apiUrl, authToken, targetSampleRate, debug) {
        return __awaiter(this, void 0, void 0, function* () {
            this.worker.postMessage({
                type: 'INIT',
                apiUrl,
                authToken,
                targetSampleRate,
                debug,
            });
            // Reset
            this.startCbs = [];
            this.stopCbs = [];
            return new Promise(resolve => {
                this.resolveInitialization = resolve;
            });
        });
    }
    setSourceSampleRate(sourceSampleRate) {
        return __awaiter(this, void 0, void 0, function* () {
            this.worker.postMessage({
                type: 'SET_SOURSE_SAMPLE_RATE',
                sourceSampleRate,
            });
            return new Promise(resolve => {
                this.resolveSourceSampleRateSet = resolve;
            });
        });
    }
    close() {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => {
                this.worker.postMessage({
                    type: 'CLOSE',
                    code: 1000,
                    message: 'Client has ended the session',
                });
                resolve();
            });
        });
    }
    startContext(appId) {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => {
                this.startCbs.push((err, id) => {
                    if (err !== undefined) {
                        reject(err);
                    }
                    else {
                        resolve(id);
                    }
                });
                if (appId != null) {
                    this.worker.postMessage({ type: 'START_CONTEXT', appId });
                }
                else {
                    this.worker.postMessage({ type: 'START_CONTEXT' });
                }
            });
        });
    }
    stopContext() {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => {
                this.stopCbs.push((err, id) => {
                    if (err !== undefined) {
                        reject(err);
                    }
                    else {
                        resolve(id);
                    }
                });
                this.worker.postMessage({ type: 'STOP_CONTEXT' });
            });
        });
    }
    switchContext(appId) {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve, reject) => {
                this.startCbs.push((err, id) => {
                    if (err !== undefined) {
                        reject(err);
                    }
                    else {
                        resolve(id);
                    }
                });
                this.worker.postMessage({ type: 'SWITCH_CONTEXT', appId });
            });
        });
    }
    postMessage(message) {
        this.worker.postMessage(message);
    }
    sendAudio(audioChunk) {
        this.worker.postMessage({ type: 'AUDIO', payload: audioChunk });
    }
}

class LocalStorage {
    constructor() {
        this.storage = window.localStorage;
    }
    get(key) {
        const val = this.storage.getItem(key);
        return val;
    }
    set(key, val) {
        this.storage.setItem(key, val);
    }
    getOrSet(key, genFn) {
        let val = this.storage.getItem(key);
        if (val === null) {
            val = genFn();
            this.storage.setItem(key, val);
        }
        return val;
    }
}

/**
 * Error to be thrown if storage API is not supported by the device.
 * @public
 */
const ErrNoStorageSupport = new Error('Current device does not support storage API');
/**
 * Error to be thrown if requested key was not found in the storage.
 * @public
 */
const ErrKeyNotFound = new Error('Requested key was not present in storage');

class SegmentState {
    constructor(ctxId, sId) {
        this.isFinalized = false;
        this.words = [];
        this.entities = new Map();
        this.intent = { intent: '', isFinal: false };
        this.contextId = ctxId;
        this.id = sId;
    }
    toSegment() {
        let i = 0;
        const entities = new Array(this.entities.size);
        this.entities.forEach(v => {
            entities[i] = v;
            i++;
        });
        return {
            id: this.id,
            contextId: this.contextId,
            isFinal: this.isFinalized,
            words: this.words,
            entities: entities,
            intent: this.intent,
        };
    }
    toString() {
        const segment = this.toSegment();
        const words = segment.words.filter((w) => w.value).map((w) => ({ value: w.value, index: w.index }));
        const cleanSegment = Object.assign(Object.assign({}, segment), { words });
        return JSON.stringify(cleanSegment, null, 2);
    }
    updateTranscript(words) {
        words.forEach(w => {
            // Only accept tentative words if the segment is tentative.
            if (!this.isFinalized || w.isFinal) {
                this.words[w.index] = w;
            }
        });
        return this;
    }
    updateEntities(entities) {
        entities.forEach(e => {
            // Only accept tentative entities if the segment is tentative.
            if (!this.isFinalized || e.isFinal) {
                this.entities.set(entityMapKey(e), e);
            }
        });
        return this;
    }
    updateIntent(intent) {
        // Only accept tentative intent if the segment is tentative.
        if (!this.isFinalized || intent.isFinal) {
            this.intent = intent;
        }
        return this;
    }
    finalize() {
        // Filter away any entities which were not finalized.
        this.entities.forEach((val, key) => {
            if (!val.isFinal) {
                this.entities.delete(key);
            }
        });
        // Filter away any transcripts which were not finalized.
        this.words = this.words.filter(w => w.isFinal);
        if (!this.intent.isFinal) {
            this.intent.intent = '';
            this.intent.isFinal = true;
        }
        // Mark as final.
        this.isFinalized = true;
        return this;
    }
}
function entityMapKey(e) {
    return `${e.startPosition.toString()}:${e.endPosition.toString()}`;
}

function parseTentativeTranscript(data) {
    return data.words.map(({ word, index, start_timestamp, end_timestamp }) => {
        return {
            value: word,
            index: index,
            startTimestamp: start_timestamp,
            endTimestamp: end_timestamp,
            isFinal: false,
        };
    });
}
function parseTranscript(data) {
    return {
        value: data.word,
        index: data.index,
        startTimestamp: data.start_timestamp,
        endTimestamp: data.end_timestamp,
        isFinal: true,
    };
}
function parseTentativeEntities(data) {
    return data.entities.map(({ entity, value, start_position, end_position }) => {
        return {
            type: entity,
            value: value,
            startPosition: start_position,
            endPosition: end_position,
            isFinal: false,
        };
    });
}
function parseEntity(data) {
    return {
        type: data.entity,
        value: data.value,
        startPosition: data.start_position,
        endPosition: data.end_position,
        isFinal: true,
    };
}
function parseIntent(data, isFinal) {
    return {
        intent: data.intent,
        isFinal: isFinal,
    };
}

const deviceIdStorageKey = 'speechly-device-id';
const authTokenKey = 'speechly-auth-token';
const defaultApiUrl = 'wss://api.speechly.com/ws/v1';
const defaultLoginUrl = 'https://api.speechly.com/login';
/**
 * A client for Speechly Spoken Language Understanding (SLU) API. The client handles initializing the microphone
 * and websocket connection to Speechly API, passing control events and audio stream to the API, reading the responses
 * and dispatching them, as well as providing a high-level API for interacting with so-called speech segments.
 * @public
 */
class Client {
    constructor(options) {
        var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l;
        this.listening = false;
        this.activeContexts = new Map();
        this.maxReconnectAttemptCount = 10;
        this.contextStopDelay = 250;
        this.connectAttempt = 0;
        this.connectPromise = null;
        this.initializePromise = null;
        this.listeningPromise = null;
        this.state = ClientState.Disconnected;
        this.stateChangeCb = () => { };
        this.segmentChangeCb = () => { };
        this.tentativeTranscriptCb = () => { };
        this.tentativeEntitiesCb = () => { };
        this.tentativeIntentCb = () => { };
        this.transcriptCb = () => { };
        this.entityCb = () => { };
        this.intentCb = () => { };
        this.handleWebsocketResponse = (response) => {
            var _a;
            if (this.debug) {
                console.log('[SpeechlyClient]', 'Received response', response);
            }
            const { audio_context, segment_id, type } = response;
            let { data } = response;
            const context = this.activeContexts.get(audio_context);
            if (context === undefined) {
                console.warn('[SpeechlyClient]', 'Received response for non-existent context', audio_context);
                return;
            }
            let segmentState = (_a = context.get(segment_id)) !== null && _a !== void 0 ? _a : new SegmentState(audio_context, segment_id);
            switch (type) {
                case WebsocketResponseType.TentativeTranscript:
                    data = data;
                    const words = parseTentativeTranscript(data);
                    this.tentativeTranscriptCb(audio_context, segment_id, words, data.transcript);
                    segmentState = segmentState.updateTranscript(words);
                    break;
                case WebsocketResponseType.Transcript:
                    data = data;
                    const word = parseTranscript(data);
                    this.transcriptCb(audio_context, segment_id, word);
                    segmentState = segmentState.updateTranscript([word]);
                    break;
                case WebsocketResponseType.TentativeEntities:
                    data = data;
                    const entities = parseTentativeEntities(data);
                    this.tentativeEntitiesCb(audio_context, segment_id, entities);
                    segmentState = segmentState.updateEntities(entities);
                    break;
                case WebsocketResponseType.Entity:
                    data = data;
                    const entity = parseEntity(data);
                    this.entityCb(audio_context, segment_id, entity);
                    segmentState = segmentState.updateEntities([entity]);
                    break;
                case WebsocketResponseType.TentativeIntent:
                    data = data;
                    const tentativeIntent = parseIntent(data, false);
                    this.tentativeIntentCb(audio_context, segment_id, tentativeIntent);
                    segmentState = segmentState.updateIntent(tentativeIntent);
                    break;
                case WebsocketResponseType.Intent:
                    data = data;
                    const intent = parseIntent(data, true);
                    this.intentCb(audio_context, segment_id, intent);
                    segmentState = segmentState.updateIntent(intent);
                    break;
                case WebsocketResponseType.SegmentEnd:
                    segmentState = segmentState.finalize();
                    break;
                // TODO: handle unexpected response types.
            }
            // Update the segment in current context.
            context.set(segment_id, segmentState);
            // Update current contexts.
            this.activeContexts.set(audio_context, context);
            // Log segment to console
            if (this.logSegments) {
                console.info(segmentState.toString());
            }
            // Fire segment change event.
            this.segmentChangeCb(segmentState.toSegment());
        };
        this.handleWebsocketClosure = (err) => {
            if (err.code === 1000) {
                if (this.debug) {
                    console.log('[SpeechlyClient]', 'Websocket closed', err);
                }
            }
            else {
                console.error('[SpeechlyClient]', 'Websocket closed due to error', err);
                // If for some reason deviceId is missing, there's nothing else we can do but fail completely.
                if (this.deviceId === undefined) {
                    this.setState(ClientState.Failed);
                    return;
                }
                // Reset
                this.listening = false;
                this.listeningPromise = null;
                this.microphone.mute();
                this.setState(ClientState.Disconnected);
                // eslint-disable-next-line @typescript-eslint/no-floating-promises
                this.reconnect();
            }
        };
        this.sampleRate = (_a = options.sampleRate) !== null && _a !== void 0 ? _a : DefaultSampleRate;
        try {
            const constraints = window.navigator.mediaDevices.getSupportedConstraints();
            this.nativeResamplingSupported = constraints.sampleRate === true;
            if (options.autoGainControl != null && options.autoGainControl) {
                // @ts-ignore
                this.autoGainControl = constraints.autoGainControl === true;
            }
            else {
                this.autoGainControl = false;
            }
        }
        catch (_m) {
            this.nativeResamplingSupported = false;
            this.autoGainControl = false;
        }
        this.debug = (_b = options.debug) !== null && _b !== void 0 ? _b : false;
        this.logSegments = (_c = options.logSegments) !== null && _c !== void 0 ? _c : false;
        this.loginUrl = (_d = options.loginUrl) !== null && _d !== void 0 ? _d : defaultLoginUrl;
        this.appId = (_e = options.appId) !== null && _e !== void 0 ? _e : undefined;
        this.projectId = (_f = options.projectId) !== null && _f !== void 0 ? _f : undefined;
        this.apiClient = (_g = options.apiClient) !== null && _g !== void 0 ? _g : new WebWorkerController();
        this.apiUrl = generateWsUrl((_h = options.apiUrl) !== null && _h !== void 0 ? _h : defaultApiUrl, (_j = options.sampleRate) !== null && _j !== void 0 ? _j : DefaultSampleRate);
        if (this.appId !== undefined && this.projectId !== undefined) {
            throw Error('[SpeechlyClient] You cannot use both appId and projectId at the same time');
        }
        this.storage = (_k = options.storage) !== null && _k !== void 0 ? _k : new LocalStorage();
        this.deviceId = this.storage.getOrSet(deviceIdStorageKey, v4);
        if (window.AudioContext !== undefined) {
            this.isWebkit = false;
        }
        else if (window.webkitAudioContext !== undefined) {
            this.isWebkit = true;
        }
        else {
            throw ErrDeviceNotSupported;
        }
        this.microphone =
            (_l = options.microphone) !== null && _l !== void 0 ? _l : new BrowserMicrophone(this.isWebkit, this.sampleRate, this.apiClient, this.debug);
        this.apiClient.onResponse(this.handleWebsocketResponse);
        this.apiClient.onClose(this.handleWebsocketClosure);
        window.SpeechlyClient = this;
        if (options.connect !== false) {
            // eslint-disable-next-line @typescript-eslint/no-floating-promises
            this.connect();
        }
    }
    getReconnectDelayMs(attempt) {
        return Math.pow(2, attempt) * 100;
    }
    sleep(ms) {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise(resolve => setTimeout(resolve, ms));
        });
    }
    /**
     * @returns true if startContext is called and expecting stopContext next
     */
    isListening() {
        return this.listening;
    }
    /**
     * Connect to Speechly backend.
     * This function will be called by initialize if not manually called earlier.
     * Calling connect() immediately after constructor and setting callbacks allows
     * prewarming the connection, resulting in less noticeable waits for the user.
     */
    connect() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.connectPromise === null) {
                this.connectPromise = (() => __awaiter(this, void 0, void 0, function* () {
                    this.advanceState(ClientState.Connecting);
                    // Get auth token from cache or renew it
                    const storedToken = this.storage.get(authTokenKey);
                    if (storedToken == null || !validateToken(storedToken, this.projectId, this.appId, this.deviceId)) {
                        try {
                            this.authToken = yield fetchToken(this.loginUrl, this.projectId, this.appId, this.deviceId);
                            // Cache the auth token in local storage for future use.
                            this.storage.set(authTokenKey, this.authToken);
                        }
                        catch (err) {
                            this.setState(ClientState.Failed);
                            throw err;
                        }
                    }
                    else {
                        this.authToken = storedToken;
                    }
                    // Establish websocket connection
                    try {
                        yield this.apiClient.initialize(this.apiUrl, this.authToken, this.sampleRate, this.debug);
                    }
                    catch (err) {
                        this.setState(ClientState.Failed);
                        throw err;
                    }
                }))();
            }
            yield this.connectPromise;
            this.advanceState(ClientState.Preinitialized);
        });
    }
    /**
     * Initializes the client, by initializing the microphone and establishing connection to the API.
     *
     * This function HAS to be invoked by a user by e.g. binding it to a button press,
     * or some other user-performed action.
     *
     * If this function is invoked without a user interaction,
     * the microphone functionality will not work due to security restrictions by the browser.
     */
    initialize() {
        return __awaiter(this, void 0, void 0, function* () {
            // Ensure we're connected. Returns immediately if we are
            if (this.initializePromise === null) {
                this.initializePromise = (() => __awaiter(this, void 0, void 0, function* () {
                    yield this.connect();
                    this.advanceState(ClientState.Initializing);
                    try {
                        if (this.isWebkit) {
                            if (window.webkitAudioContext !== undefined) {
                                // eslint-disable-next-line new-cap
                                this.audioContext = new window.webkitAudioContext();
                            }
                        }
                        else {
                            const opts = {};
                            if (this.nativeResamplingSupported) {
                                opts.sampleRate = this.sampleRate;
                            }
                            this.audioContext = new window.AudioContext(opts);
                        }
                        const mediaStreamConstraints = {
                            video: false,
                        };
                        if (this.nativeResamplingSupported || this.autoGainControl) {
                            mediaStreamConstraints.audio = {
                                sampleRate: this.sampleRate,
                                // @ts-ignore
                                autoGainControl: this.autoGainControl,
                            };
                        }
                        else {
                            mediaStreamConstraints.audio = true;
                        }
                        if (this.audioContext != null) {
                            // Start audio context if we are dealing with a WebKit browser.
                            //
                            // WebKit browsers (e.g. Safari) require to resume the context first,
                            // before obtaining user media by calling `mediaDevices.getUserMedia`.
                            //
                            // If done in a different order, the audio context will resume successfully,
                            // but will emit empty audio buffers.
                            if (this.isWebkit) {
                                yield this.audioContext.resume();
                            }
                            yield this.apiClient.setSourceSampleRate(this.audioContext.sampleRate);
                            yield this.microphone.initialize(this.audioContext, mediaStreamConstraints);
                            this.advanceState(ClientState.Connected);
                        }
                        else {
                            throw ErrDeviceNotSupported;
                        }
                    }
                    catch (err) {
                        switch (err) {
                            case ErrDeviceNotSupported:
                                this.setState(ClientState.NoBrowserSupport);
                                break;
                            case ErrNoAudioConsent:
                                this.setState(ClientState.NoAudioConsent);
                                break;
                            default:
                                this.setState(ClientState.Failed);
                        }
                        throw err;
                    }
                }))();
            }
            yield this.initializePromise;
            this.advanceState(ClientState.Connected);
        });
    }
    /**
     * Closes the client by closing the API connection and disabling the microphone.
     */
    close() {
        return __awaiter(this, void 0, void 0, function* () {
            const errs = [];
            try {
                yield this.microphone.close();
            }
            catch (err) {
                // @ts-ignore
                errs.push(err.message);
            }
            try {
                yield this.apiClient.close();
            }
            catch (err) {
                // @ts-ignore
                errs.push(err.message);
            }
            this.activeContexts.clear();
            this.connectPromise = null;
            this.initializePromise = null;
            this.setState(ClientState.Disconnected);
            if (errs.length > 0) {
                throw Error(errs.join(','));
            }
        });
    }
    hasUnrecoverableError() {
        return this.state < ClientState.__UnrecoverableErrors;
    }
    queueTask(task) {
        return __awaiter(this, void 0, void 0, function* () {
            const prevTask = this.listeningPromise;
            this.listeningPromise = (() => __awaiter(this, void 0, void 0, function* () {
                yield prevTask;
                return task();
            }))();
            return this.listeningPromise;
        });
    }
    /**
     * Starts a new SLU context by sending a start context event to the API and unmuting the microphone.
     * @param cb - the callback which is invoked when the context start was acknowledged by the API.
     */
    startContext(appId) {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.hasUnrecoverableError()) {
                if (this.listening) {
                    throw Error('Already listening');
                }
                this.listening = true;
                const contextId = yield this.queueTask(() => __awaiter(this, void 0, void 0, function* () {
                    if (this.state < ClientState.Connected) {
                        yield this.initialize();
                    }
                    if (this.state !== ClientState.Connected) {
                        throw Error('[SpeechlyClient] Unable to complete startContext: Expected Connected state, but was in ' + stateToString(this.state) + '. Did you call startContext multiple times without stopContext?');
                    }
                    this.setState(ClientState.Starting);
                    this.microphone.unmute();
                    // Fetch context id
                    let contextId;
                    if (this.projectId != null) {
                        contextId = yield this.apiClient.startContext(appId);
                    }
                    else {
                        if (appId != null && this.appId !== appId) {
                            this.setState(ClientState.Failed);
                            throw ErrAppIdChangeWithoutProjectLogin;
                        }
                        contextId = yield this.apiClient.startContext();
                    }
                    // Ensure state has not been changed by await apiClient.startContext() due to websocket errors.
                    // Due to apiClient.startContext implementation, they don't throw an error here, but call handleWebsocketClosure instead which changes to ClientState.Disconnected
                    // @ts-ignore
                    if (this.state !== ClientState.Starting) {
                        throw Error('[SpeechlyClient] Unable to complete startContext: Problem acquiring contextId');
                    }
                    this.activeContexts.set(contextId, new Map());
                    this.setState(ClientState.Recording);
                    return contextId;
                }));
                return contextId;
            }
            throw Error('[SpeechlyClient] startContext cannot be run in unrecovable error state.');
        });
    }
    /**
     * Stops current SLU context by sending a stop context event to the API and muting the microphone
     * delayed by contextStopDelay = 250 ms
     */
    stopContext() {
        return __awaiter(this, void 0, void 0, function* () {
            if (!this.hasUnrecoverableError()) {
                if (!this.listening) {
                    throw Error('Already stopped listening');
                }
                this.listening = false;
                const contextId = yield this.queueTask(() => __awaiter(this, void 0, void 0, function* () {
                    if (this.state !== ClientState.Recording) {
                        throw Error('[SpeechlyClient] Unable to complete stopContext: Expected Recording state, but was in ' + stateToString(this.state) + '.');
                    }
                    this.setState(ClientState.Stopping);
                    yield this.sleep(this.contextStopDelay);
                    this.microphone.mute();
                    try {
                        const contextId = yield this.apiClient.stopContext();
                        this.activeContexts.delete(contextId);
                        this.setState(ClientState.Connected);
                        return contextId;
                    }
                    catch (err) {
                        this.setState(ClientState.Failed);
                        throw err;
                    }
                }));
                return contextId;
            }
            throw Error('[SpeechlyClient] stopContext cannot be run in unrecovable error state.');
        });
    }
    /**
     * Stops current context and immediately starts a new SLU context
     * by sending a start context event to the API and unmuting the microphone.
     * @param appId - unique identifier of an app in the dashboard.
     */
    switchContext(appId) {
        return __awaiter(this, void 0, void 0, function* () {
            yield this.queueTask(() => __awaiter(this, void 0, void 0, function* () {
                if (this.state !== ClientState.Recording) {
                    throw Error('[SpeechlyClient] Unable to complete switchContext: Expected Recording state, but was in ' + stateToString(this.state) + '.');
                }
                const contextId = yield this.apiClient.switchContext(appId);
                this.activeContexts.set(contextId, new Map());
            }));
        });
    }
    /**
     * Adds a listener for client state change events.
     * @param cb - the callback to invoke on state change events.
     */
    onStateChange(cb) {
        this.stateChangeCb = cb;
    }
    /**
     * Adds a listener for current segment change events.
     * @param cb - the callback to invoke on segment change events.
     */
    onSegmentChange(cb) {
        this.segmentChangeCb = cb;
    }
    /**
     * Adds a listener for tentative transcript responses from the API.
     * @param cb - the callback to invoke on a tentative transcript response.
     */
    onTentativeTranscript(cb) {
        this.tentativeTranscriptCb = cb;
    }
    /**
     * Adds a listener for transcript responses from the API.
     * @param cb - the callback to invoke on a transcript response.
     */
    onTranscript(cb) {
        this.transcriptCb = cb;
    }
    /**
     * Adds a listener for tentative entities responses from the API.
     * @param cb - the callback to invoke on a tentative entities response.
     */
    onTentativeEntities(cb) {
        this.tentativeEntitiesCb = cb;
    }
    /**
     * Adds a listener for entity responses from the API.
     * @param cb - the callback to invoke on an entity response.
     */
    onEntity(cb) {
        this.entityCb = cb;
    }
    /**
     * Adds a listener for tentative intent responses from the API.
     * @param cb - the callback to invoke on a tentative intent response.
     */
    onTentativeIntent(cb) {
        this.tentativeIntentCb = cb;
    }
    /**
     * Adds a listener for intent responses from the API.
     * @param cb - the callback to invoke on an intent response.
     */
    onIntent(cb) {
        this.intentCb = cb;
    }
    reconnect() {
        return __awaiter(this, void 0, void 0, function* () {
            if (this.debug) {
                console.log('[SpeechlyClient]', 'Reconnecting...', this.connectAttempt);
            }
            this.connectPromise = null;
            if (!this.hasUnrecoverableError() && this.connectAttempt < this.maxReconnectAttemptCount) {
                yield this.sleep(this.getReconnectDelayMs(this.connectAttempt++));
                // eslint-disable-next-line @typescript-eslint/no-floating-promises
                yield this.connect();
            }
            else {
                console.error('[SpeechlyClient] Maximum reconnect count reached, giving up automatic reconnect.');
            }
        });
    }
    advanceState(newState) {
        if (this.state >= newState) {
            return;
        }
        this.setState(newState);
    }
    setState(newState) {
        if (this.state === newState) {
            return;
        }
        if (this.debug) {
            console.log('[SpeechlyClient]', stateToString(this.state), '->', stateToString(newState));
        }
        this.state = newState;
        this.stateChangeCb(newState);
    }
    /**
     * print statistics to console
     */
    printStats() {
        this.microphone.printStats();
    }
    sendAudioData(audioData) {
        return __awaiter(this, void 0, void 0, function* () {
            const audioBuffer = yield this.audioContext.decodeAudioData(audioData);
            const samples = audioBuffer.getChannelData(0);
            // convert 2-channel audio to 1-channel if need be
            if (audioBuffer.numberOfChannels > 1) {
                const chan1samples = audioBuffer.getChannelData(1);
                for (let i = 0; i < samples.length; i++) {
                    samples[i] = (samples[i] + chan1samples[i]) / 2.0;
                }
            }
            this.listening = true;
            this.setState(ClientState.Starting);
            const contextId = yield this.apiClient.startContext();
            this.activeContexts.set(contextId, new Map());
            this.setState(ClientState.Recording);
            let sendBuffer;
            for (let b = 0; b < samples.length; b += 16000) {
                const e = b + 16000;
                if (e > samples.length) {
                    sendBuffer = samples.slice(b);
                }
                else {
                    sendBuffer = samples.slice(b, e);
                }
                this.apiClient.sendAudio(sendBuffer);
            }
            this.listening = false;
            this.setState(ClientState.Stopping);
            yield this.apiClient.stopContext();
            this.activeContexts.delete(contextId);
            this.setState(ClientState.Connected);
        });
    }
}
function generateWsUrl(baseUrl, sampleRate) {
    const params = new URLSearchParams();
    params.append('sampleRate', sampleRate.toString());
    return `${baseUrl}?${params.toString()}`;
}

export { Client, ClientState, DefaultSampleRate, ErrAlreadyInitialized, ErrAppIdChangeWithoutProjectLogin, ErrDeviceNotSupported, ErrKeyNotFound, ErrNoAudioConsent, ErrNoStorageSupport, ErrNotInitialized, WebsocketResponseType, stateToString };
//# sourceMappingURL=speechly.es.js.map
